{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555d7d57-91de-45f5-aac4-db021e7c23ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is an example of performing Hybrid search using sqlite-vec and FTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a66748-a152-43a3-9a5a-2e726bc8a01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade pip\n",
    "# !pip install sqlite-vec\n",
    "# !pip install pandas\n",
    "# !pip install openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c1a669a-c807-41fa-96d3-67f2e53bbc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import sqlite_vec\n",
    "from typing import List\n",
    "import struct\n",
    "import pandas as pd\n",
    "from openai import AzureOpenAI, OpenAIError  \n",
    "import openai \n",
    "import json\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4a98670-b065-4e12-a077-223ecb521c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k = 10\n",
    "openai_embedding_api_base = \"https://<redacted>.openai.azure.com/\"\n",
    "openai_embedding_api_key = \"<redacted>\"\n",
    "openai_embedding_api_version =  \"2024-02-15-preview\"\n",
    "openai_embedding_model = \"text-embedding-ada-002\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa9b0d4c-5517-46ff-a745-9aa1726ccf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to serialize float32 list to binary format compatible with sqlite-vec  \n",
    "def serialize_f32(vec):  \n",
    "    return np.array(vec, dtype=np.float32).tobytes()  \n",
    "\n",
    "def reciprocal_rank_fusion(fts_results, vec_results, k=60):  \n",
    "    rank_dict = {}  \n",
    "  \n",
    "    # Process FTS results  \n",
    "    for rank, (id,) in enumerate(fts_results):  \n",
    "        if id not in rank_dict:  \n",
    "            rank_dict[id] = 0  \n",
    "        rank_dict[id] += 1 / (k + rank + 1)  \n",
    "  \n",
    "    # Process vector results  \n",
    "    for rank, (rowid, distance) in enumerate(vec_results):  \n",
    "        if rowid not in rank_dict:  \n",
    "            rank_dict[rowid] = 0  \n",
    "        rank_dict[rowid] += 1 / (k + rank + 1)  \n",
    "  \n",
    "    # Sort by RRF score  \n",
    "    sorted_results = sorted(rank_dict.items(), key=lambda x: x[1], reverse=True)  \n",
    "    return sorted_results \n",
    "  \n",
    "def or_words(input_string):  \n",
    "    # Split the input string into words  \n",
    "    words = input_string.split()  \n",
    "      \n",
    "    # Join the words with ' OR ' in between  \n",
    "    result = ' OR '.join(words)  \n",
    "      \n",
    "    return result\n",
    "\n",
    "def lookup_row(id):\n",
    "    row_lookup = cur.execute('''  \n",
    "    SELECT content FROM mango_lookup WHERE id = ?\n",
    "    ''', (id,)).fetchall()  \n",
    "    content = ''\n",
    "    for row in row_lookup:\n",
    "        content= row[0]\n",
    "        break\n",
    "    return content\n",
    "\n",
    "# Function to generate vectors for text  \n",
    "def generate_embedding(text):  \n",
    "    max_attempts = 6  \n",
    "    max_backoff = 60  \n",
    "    if text is None:  \n",
    "        return None  \n",
    "  \n",
    "    client = AzureOpenAI(  \n",
    "        api_version=openai_embedding_api_version,  \n",
    "        azure_endpoint=openai_embedding_api_base,  \n",
    "        api_key=openai_embedding_api_key  \n",
    "    )  \n",
    "  \n",
    "    counter = 0  \n",
    "    incremental_backoff = 1  # seconds to wait on throttling - this will be incremental backoff  \n",
    "    while counter < max_attempts:  \n",
    "        try:  \n",
    "            response = client.embeddings.create(  \n",
    "                input=text,  \n",
    "                model=openai_embedding_model  \n",
    "            )  \n",
    "            return json.loads(response.model_dump_json())[\"data\"][0]['embedding']  \n",
    "        except OpenAIError as ex:  \n",
    "            if str(ex.code) == \"429\":  \n",
    "                print('OpenAI Throttling Error - Waiting to retry after', incremental_backoff, 'seconds...')  \n",
    "                incremental_backoff = min(max_backoff, incremental_backoff * 1.5)  \n",
    "                counter += 1  \n",
    "                time.sleep(incremental_backoff)  \n",
    "            elif str(ex.code) == \"DeploymentNotFound\":  \n",
    "                print('Error: Deployment not found')  \n",
    "                return 'Error: Deployment not found'  \n",
    "            elif 'Error code: 40' in str(ex):  \n",
    "                print('Error: ' + str(ex))  \n",
    "                return 'Error:' + str(ex)  \n",
    "            elif 'Connection error' in str(ex):  \n",
    "                print('Error: Connection error')  \n",
    "                return 'Error: Connection error'  \n",
    "            elif str(ex.code) == \"content_filter\":  \n",
    "                print('Content Filter Error', ex.code)  \n",
    "                return \"Error: Content could not be extracted due to Azure OpenAI content filter.\" + ex.code  \n",
    "            else:  \n",
    "                print('API Error:', ex)  \n",
    "                print('API Error Code:', ex.code)  \n",
    "                incremental_backoff = min(max_backoff, incremental_backoff * 1.5)  \n",
    "                counter += 1  \n",
    "                time.sleep(incremental_backoff)  \n",
    "        except Exception as ex:  \n",
    "            counter += 1  \n",
    "            print('Error - Retry count:', counter, ex)  \n",
    "            return None  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f5d60e3-f030-4403-a2e1-9727919753c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sqlite_version=3.40.1, vec_version=v0.1.1\n"
     ]
    }
   ],
   "source": [
    "# Create an in memory sqlite db\n",
    "db = sqlite3.connect(\":memory:\")\n",
    "db.enable_load_extension(True)\n",
    "sqlite_vec.load(db)\n",
    "db.enable_load_extension(False)\n",
    "\n",
    "sqlite_version, vec_version = db.execute(\n",
    "    \"select sqlite_version(), vec_version()\"\n",
    ").fetchone()\n",
    "print(f\"sqlite_version={sqlite_version}, vec_version={vec_version}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85c86294-6699-4de7-b1b2-5d3ff9473a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dims in Vector Embeddings: 1536\n"
     ]
    }
   ],
   "source": [
    "test_vec = generate_embedding('The quick brown fox')\n",
    "dims = len(test_vec)\n",
    "print ('Dims in Vector Embeddings:', dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6ddf350-058d-4317-bbc8-b99845ebaf4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x776b84f1aec0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur = db.cursor()\n",
    "cur.execute('CREATE VIRTUAL TABLE mango_fts USING fts5(id UNINDEXED, content, tokenize=\"porter unicode61\");')\n",
    "\n",
    "# sqlite-vec always adds an ID field\n",
    "cur.execute('''CREATE VIRTUAL TABLE mango_vec USING vec0(embedding float[''' + str(dims) + '])''')  \n",
    "\n",
    "# Create a content lookup table with an index on the ID  \n",
    "cur.execute('CREATE TABLE mango_lookup (id INTEGER PRIMARY KEY, content TEXT);')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b7e4eca-43c8-43c0-a3d3-952f2305ad46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert some sample data into mango_fts  \n",
    "fts_data = [  \n",
    "    (1, 'The quick brown fox jumps over the lazy dog.'),  \n",
    "    (2, 'Artificial intelligence is transforming the world.'),  \n",
    "    (3, 'Climate change is a pressing global issue.'),  \n",
    "    (4, 'The stock market fluctuates based on various factors.'),  \n",
    "    (5, 'Remote work has become more prevalent during the pandemic.'),  \n",
    "    (6, 'Electric vehicles are becoming more popular.'),  \n",
    "    (7, 'Quantum computing has the potential to revolutionize technology.'),  \n",
    "    (8, 'Healthcare innovation is critical for societal well-being.'),  \n",
    "    (9, 'Space exploration expands our understanding of the universe.'),  \n",
    "    (10, 'Cybersecurity threats are evolving and becoming more sophisticated.')  \n",
    "] \n",
    "  \n",
    "cur.executemany('''  \n",
    "INSERT INTO mango_fts (id, content) VALUES (?, ?)  \n",
    "''', fts_data)  \n",
    "\n",
    "\n",
    "cur.executemany('''  \n",
    "  INSERT INTO mango_lookup (id, content) VALUES (?, ?)  \n",
    "''', fts_data)  \n",
    "  \n",
    "\n",
    "# Generate embeddings for the content and insert into mango_vec  \n",
    "for row in fts_data:  \n",
    "    id, content = row  \n",
    "    embedding = generate_embedding(content)\n",
    "    cur.execute('''  \n",
    "    INSERT INTO mango_vec (rowid, embedding) VALUES (?, ?)  \n",
    "    ''', (id, serialize_f32(embedding)))  \n",
    "\n",
    "\n",
    "# Commit changes  \n",
    "db.commit()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ed8a288-9e8f-4524-808c-f94d6aaa807d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 8, Content: Healthcare innovation is critical for societal well-being., RRF Score: 0.01639344262295082\n",
      "ID: 2, Content: Artificial intelligence is transforming the world., RRF Score: 0.016129032258064516\n",
      "ID: 9, Content: Space exploration expands our understanding of the universe., RRF Score: 0.015873015873015872\n",
      "ID: 1, Content: The quick brown fox jumps over the lazy dog., RRF Score: 0.015625\n",
      "ID: 5, Content: Remote work has become more prevalent during the pandemic., RRF Score: 0.015384615384615385\n",
      "ID: 10, Content: Cybersecurity threats are evolving and becoming more sophisticated., RRF Score: 0.015151515151515152\n",
      "ID: 7, Content: Quantum computing has the potential to revolutionize technology., RRF Score: 0.014925373134328358\n",
      "ID: 6, Content: Electric vehicles are becoming more popular., RRF Score: 0.014705882352941176\n",
      "ID: 3, Content: Climate change is a pressing global issue., RRF Score: 0.014492753623188406\n",
      "ID: 4, Content: The stock market fluctuates based on various factors., RRF Score: 0.014285714285714285\n"
     ]
    }
   ],
   "source": [
    "# Full-text search query  \n",
    "fts_search_query = \"AI\"  \n",
    "# fts_search_query = \"technology innovation\"  \n",
    "# fts_search_query = \"electricity cars\"  \n",
    "# fts_search_query = \"medical\"  \n",
    "\n",
    "fts_results = cur.execute('''  \n",
    "  SELECT id FROM mango_fts WHERE mango_fts MATCH ? ORDER BY rank limit 5  \n",
    "''', (or_words(fts_search_query),)).fetchall()  \n",
    "  \n",
    "# Vector search query  \n",
    "query_embedding = generate_embedding(fts_search_query)  \n",
    "vec_results = cur.execute('''  \n",
    "  SELECT rowid, distance FROM mango_vec WHERE embedding MATCH ? and K = ?  \n",
    "  ORDER BY distance  \n",
    "''', [serialize_f32(query_embedding), top_k]).fetchall()  \n",
    "  \n",
    "# Combine results using RRF  \n",
    "combined_results = reciprocal_rank_fusion(fts_results, vec_results)  \n",
    "  \n",
    "# Print combined results  \n",
    "for id, score in combined_results:  \n",
    "    print(f'ID: {id}, Content: {lookup_row(id)}, RRF Score: {score}')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd42c82-d7ab-4a60-a1dc-1deae4d3f815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the connection  \n",
    "db.close()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0e5b5f-b593-4cf7-a53e-cf02a41539f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
